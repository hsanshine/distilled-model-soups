{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:01, 8764583.47it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 6830493.64it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:00, 4029193.11it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 12132675.98it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0, 0.5),\n",
    "])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Teacher, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.leakyrelu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2) # padding 'same' do not exit...\n",
    "        \n",
    "        self.dense = torch.nn.Linear(4*4*512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.leakyrelu(output)\n",
    "        output = self.max_pool(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.dense(output.view(output.size(0), -1))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class Student(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Student, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.leakyrelu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2) # padding 'same' do not exit...\n",
    "        \n",
    "        self.dense = torch.nn.Linear(4*4*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.leakyrelu(output)\n",
    "        output = self.max_pool(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.dense(output.view(output.size(0), -1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = Teacher().to(device)\n",
    "student = Student().to(device)\n",
    "student_scratch = Student().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_opt = torch.optim.Adam(teacher.parameters(), lr=0.001)\n",
    "student_opt = torch.optim.Adam(student.parameters(), lr=0.001)\n",
    "student_scratch_opt = torch.optim.Adam(student_scratch.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "distill_criterion = torch.nn.KLDivLoss(reduction='batchmean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Pytorch KL-Divergence 실험 (feat. log_softmax와 softmax 무엇이 맞는지)\n",
    "- https://douglasrizzo.com.br/kl-div-pytorch/\n",
    "\n",
    "<div align='center'>\n",
    "    <img width=\"400\" src=\"https://www.oreilly.com/library/view/generative-adversarial-networks/9781789136678/assets/3ed12abb-fb0d-4205-848a-928127ec92ca.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, dataloader, criterion, optimizer, teacher_model=None, \n",
    "    distill_criterion=None, alpha=0.1, temperature=10, device='cpu'\n",
    "):\n",
    "    if teacher_model!=None:\n",
    "        teacher_model.eval()\n",
    "        \n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    for idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # predict\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if teacher_model != None:\n",
    "            teacher_outputs = teacher_model(inputs)\n",
    "            \n",
    "        # loss and update\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        if teacher_model != None:\n",
    "            student_outputs = torch.nn.functional.log_softmax(outputs / temperature, dim=1) # log softmax\n",
    "            teacher_outputs = torch.nn.functional.softmax(teacher_outputs / temperature, dim=1) # softmax\n",
    "            \n",
    "            distill_loss = distill_criterion(student_outputs, teacher_outputs)\n",
    "            \n",
    "            loss = alpha * loss + (1 - alpha) * distill_loss \n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # total loss and acc\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        preds = outputs.argmax(dim=1) \n",
    "        correct += targets.eq(preds).sum().item()\n",
    "        total += targets.size(0)\n",
    "        \n",
    "        if idx == (len(dataloader)-1):\n",
    "            print('[%d/%d]: Loss: %.3f | Acc: %.3f%% [%d/%d]' % \n",
    "                  (idx+1, len(dataloader), total_loss/(idx+1), 100.*correct/total, correct, total),end='\\n')\n",
    "        else:\n",
    "            print('[%d/%d]: Loss: %.3f | Acc: %.3f%% [%d/%d]' % \n",
    "                  (idx+1, len(dataloader), total_loss/(idx+1), 100.*correct/total, correct, total),end='\\r')\n",
    "        \n",
    "        \n",
    "def test(model, dataloader, criterion, device='cpu'):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # predict\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # loss \n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # total loss and acc\n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += targets.eq(preds).sum().item()\n",
    "            total += targets.size(0)\n",
    "            \n",
    "            \n",
    "            if idx == (len(dataloader)-1):\n",
    "                print('[%d/%d]: Loss: %.3f | Acc: %.3f%% [%d/%d]' % \n",
    "                      (idx+1, len(dataloader), total_loss/(idx+1), 100.*correct/total, correct, total),end='\\n')\n",
    "            else:\n",
    "                print('[%d/%d]: Loss: %.3f | Acc: %.3f%% [%d/%d]' % \n",
    "                      (idx+1, len(dataloader), total_loss/(idx+1), 100.*correct/total, correct, total),end='\\r')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "[938/938]: Loss: 0.181 | Acc: 94.542% [56725/60000]\n",
      "[157/157]: Loss: 0.090 | Acc: 97.130% [9713/10000]\n",
      "Epoch: 2/5\n",
      "[938/938]: Loss: 0.097 | Acc: 97.147% [58288/60000]\n",
      "[157/157]: Loss: 0.099 | Acc: 97.110% [9711/10000]\n",
      "Epoch: 3/5\n",
      "[938/938]: Loss: 0.079 | Acc: 97.600% [58560/60000]\n",
      "[157/157]: Loss: 0.081 | Acc: 97.650% [9765/10000]\n",
      "Epoch: 4/5\n",
      "[938/938]: Loss: 0.072 | Acc: 97.795% [58677/60000]\n",
      "[157/157]: Loss: 0.081 | Acc: 97.560% [9756/10000]\n",
      "Epoch: 5/5\n",
      "[938/938]: Loss: 0.066 | Acc: 98.015% [58809/60000]\n",
      "[157/157]: Loss: 0.102 | Acc: 97.310% [9731/10000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}/{epochs}')\n",
    "    train(teacher, trainloader, criterion, teacher_opt, device=device)\n",
    "    test(teacher, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "[938/938]: Loss: 0.178 | Acc: 87.552% [52531/60000]\n",
      "[157/157]: Loss: 0.197 | Acc: 94.770% [9477/10000]\n",
      "Epoch: 2/3\n",
      "[938/938]: Loss: 0.062 | Acc: 95.352% [57211/60000]\n",
      "[157/157]: Loss: 0.130 | Acc: 96.470% [9647/10000]\n",
      "Epoch: 3/3\n",
      "[938/938]: Loss: 0.046 | Acc: 96.475% [57885/60000]\n",
      "[157/157]: Loss: 0.107 | Acc: 97.010% [9701/10000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}/{epochs}')\n",
    "    train(student, trainloader, criterion, student_opt,\n",
    "          teacher, distill_criterion, alpha=0.1, temperature=10, device=device)\n",
    "    test(student, testloader, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Scratch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "[938/938]: Loss: 0.349 | Acc: 89.823% [53894/60000]\n",
      "[157/157]: Loss: 0.142 | Acc: 95.770% [9577/10000]\n",
      "Epoch: 2/3\n",
      "[938/938]: Loss: 0.142 | Acc: 95.652% [57391/60000]\n",
      "[157/157]: Loss: 0.107 | Acc: 96.710% [9671/10000]\n",
      "Epoch: 3/3\n",
      "[938/938]: Loss: 0.115 | Acc: 96.517% [57910/60000]\n",
      "[157/157]: Loss: 0.098 | Acc: 96.760% [9676/10000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}/{epochs}')\n",
    "    train(student_scratch, trainloader, criterion, student_scratch_opt, device=device)\n",
    "    test(student_scratch, testloader, criterion, device=device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa591e11221661f1ecc8136da9d73cea554c23e0883e0d08381481ec0c2f8724"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('graduation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
